---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently an incoming M.S. student at Hangzhou Dianzi University（杭州电子科技大学）, where I am supervised by Associate Prof. Zizhao Wu (吴子朝). Before that, I received the B.S. degree in the School of Media and Design from Hangzhou Dianzi University in 2020.

My research interests includes: deep learning, computer vision, human motion prediction and video understanding.

<a href="backup/indexl.html">[中文主页]</a>

# 🔥 News
- *2023.01*: &nbsp;🎉🎉 The new homepage is built and updated. 
- *2023.02*: &nbsp;🎉🎉 One paper is accepted by CVPR 2023!

# 📝 Publications

\* indicates equal contribution 


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/TBIFormer_500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Trajectory-Aware Body Interaction Transformer for Multi-Person Pose Forecasting](https://openaccess.thecvf.com/content/CVPR2023/papers/Peng_Trajectory-Aware_Body_Interaction_Transformer_for_Multi-Person_Pose_Forecasting_CVPR_2023_paper.pdf)

**Xiaogang Peng**, Siyuan Mao, Zizhao Wu

[**Codes** ![](https://img.shields.io/github/stars/xiaogangpeng/tbiformer?style=social)](https://github.com/xiaogangpeng/tbiformer) \| [**Project Page**](https://xiaogangpeng.github.io/projects/tbiformer/page.html)
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Effectively modeling body parts interactions for the task of multi-person pose forecasting. 
</div>
</div>

- ``Under Review`` [The MI-Motion Dataset and Benchmark for 3D Multi-Person Motion Prediction](https://github.com),  **Xiaogang Peng**, Xiao Zhou, Yikai Luo, Hao Wen, Ding Yu, Zizhao Wu \| [**Project**](https://mi-motion.github.io) \| [**Baseline Codes** ![](https://img.shields.io/github/stars/xiaogangpeng/socialtgcn?style=social)](https://github.com/xiaogangpeng/socialtgcn)
- ``Under Review`` [Learning Weakly-Supervised Audio-Visual Violence Detection in Hyperbolic Space](https://github.com),  **Xiaogang Peng\***, Hao Wen\*, Yikai Luo\*, Xiao Zhou, Keyang Yu, Yigang Wang, Zizhao Wu \| [**Codes** ![](https://img.shields.io/github/stars/xiaogangpeng/HyperVD?style=social)](https://github.com/xiaogangpeng/HyperVD)




- ``Arxiv 2022`` [PointCMC: Cross-Modal Multi-Scale Correspondences Learning for Point Cloud Understanding]&#40;https://github.com&#41;, Honggu Zhou, **Xiaogang Peng**, Jiawei Mao, Zizhao Wu, Ming Zeng
- ``Arxiv 2022`` [More Comprehensive Facial Inversion for More Effective Expression Recognition]&#40;https://github.com&#41;, Jiawei Mao, Guangyi Zhao, Yuanqi Chang, Xuesong Yin, **Xiaogang Peng**, Rui Xu 


# 🎖 Honors and Awards
- *2023.06* Excellent Master's Thesis Cultivation Program (top 5%)
- *2022.09* Third-Class Graduate Academic Scholarship of Hangzhou Dianzi University
- *2021.09* Master Freshman Merit Scholarship of Hangzhou Dianzi University
- *2020.06* Outstanding Undergraduate Thesis of Hangzhou Dianzi University
- *2019.09* First-Class Academic Scholarship of Hangzhou Dianzi University
- *2019.05* Second-Award of Service Outsourcing Innovation and Entrepreneurship Competition for Chinese College Students.
- *2018.05* Third-Class Academic Scholarship of Hangzhou Dianzi University


# 📖 Educations
- *2021.09 - 2024.06 (expected)*, Master, Hangzhou Dianzi University (HDU), Hangzhou, Zhejiang. 
- *2016.09 - 2020.06*, Undergraduate, Hangzhou Dianzi University (HDU), Hangzhou, Zhejiang. 

[//]: # (# 💬 Invited Talks)

[//]: # (- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. )

[//]: # (- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]]&#40;https://github.com/&#41;)

# 💻 Internships
- I will be joining in [Dr. Huaizu Jiang](https://jianghz.me/)'s Computer Vision Lab of [Northeastern University](https://www.northeastern.edu/) as a research intern in June 2023.
- *2023.03 - 2023.07 (expected)*, [Phigent Robotics](https://www.phigent.ai/home), China.
